#!/bin/zsh


chmod +x ./back-end/generateBin
chmod +x ./SparkStreamingAnalyser/generateJAR
chmod +x ./KafkaStreamsChatAnalyser/generateJAR
chmod +x ./scripts/stopDev
chmod +x ./scripts/stopProd
chmod +x ./scripts/inspectTopics
chmod +x ./runGraphAnalyser
chmod +x ./runSparkStreamingAnalyser

kessenger_mode="prod"
generate_backend=true
generate_kafka_streams=true
restart_kessenger=false


for arr in $@ ; do

  if [[ $arr = "--gen-backend-bin=false" ]] ; then
    echo "Not generating backend binaries."
    generate_backend=false
  fi
#  if [[ $arr = "--build-spark-streaming=false" ]] ; then
#    echo "Not generating spark streaming binaries."
#    build_spark_streaming=false
#  fi
#  if [[ $arr = "--build-spark-graphx=false" ]] ; then
#    echo "Not generating spark graph binaries."
#    build_spark_graphx=false
#  fi
  if [[ $arr = "--gen-kafka-streams-bin=false" ]] ; then
    echo "Not generating kafka streams binaries."
    generate_kafka_streams=false
  fi

  if [[ $arr = "--env=dev" ]] ; then
    kessenger_mode="prod"
  fi

  if [[ $arr = "--restart" ]] ; then
    restart_kessenger=true
  fi
done


if [[ $generate_kafka_streams = true ]] ; then
  rm -rf ./KafkaStreamsChatAnalyser/target/scala-2.13
  ./KafkaStreamsChatAnalyser/generateJAR
  rm -rf $HOME/kessenger/prod/logs/kafkastreaming/application.log
fi
#if [[ $generate_spark_streaming = true ]] ; then
#  rm -rf ./SparkStreamingAnalyser/target/scala-2.12/
#  ./SparkStreamingAnalyser/generateJAR
#  rm -rf $HOME/kessenger/prod/logs/sparkanalyser/application.log
#fi


if [[ $kessenger_mode = "prod" ]] ; then
  if [[ $generate_backend = true ]] ; then
    rm -rf ./back-end/target/universal
    ./back-end/generateBin
    rm -rf $HOME/kessenger/prod/logs/backend_*/application.log
  fi
fi

if [[ $restart_kessenger = true ]] ; then
  if [[ $generate_kafka_streams = true ]] ; then
    echo "restarting kafka streams"
    docker stop kafka_streams_chat_analyser
    docker rm -v kafka_streams_chat_analyser
    docker rmi  kessenger_kafka_streams
  fi
#  if [[ $generate_spark_streaming = true ]] ; then
#    echo "restarting spark streaming"
#    # TODO tutaj sprawdzić jak się nazywają contenery
#    docker stop spark-master
#    docker rm -v spark-master
#    docker rmi kessenger_spark-master
#  fi
  if [[ $kessenger_mode = "prod" ]] ; then
    if [[ $generate_backend = true ]] ; then
      echo "restarting backend"

      docker stop play-app-1
      docker rm -v play-app-1
      docker rmi kessenger_play-app-1

      docker stop play-app-2
      docker rm -v play-app-2
      docker rmi kessenger_play-app-2

    fi
  fi
fi



if [[ $kessenger_mode = "dev" ]] ; then
  docker-compose -f docker-compose.dev.yml up -d
else
  docker-compose -f docker-compose.prod.yml up -d
fi



exit 0